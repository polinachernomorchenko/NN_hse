{"metadata":{"accelerator":"GPU","colab":{"name":"QuesT_Homework3_classification.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\n!pip install torch\n!pip install nltk\n!pip install tqdm\n!pip install seaborn\n!pip install numpy\n!pip install sklearn","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"Y0fOWhqwW-AT","outputId":"41f40fd4-ebae-43e8-fd1c-41db3fb72471","execution":{"iopub.status.busy":"2022-12-01T14:16:08.240708Z","iopub.execute_input":"2022-12-01T14:16:08.241465Z","iopub.status.idle":"2022-12-01T14:17:15.642270Z","shell.execute_reply.started":"2022-12-01T14:16:08.241319Z","shell.execute_reply":"2022-12-01T14:17:15.641023Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2022.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.64.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (0.11.2)\nRequirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.7/site-packages (from seaborn) (3.5.3)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.21.6)\nRequirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.3.5)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2022.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (1.0.2)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.6)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"u3wugeOHW-AV","outputId":"7979e6ad-bff3-4493-c0e7-a9666383f9ae","execution":{"iopub.status.busy":"2022-12-01T14:18:23.856345Z","iopub.execute_input":"2022-12-01T14:18:23.857210Z","iopub.status.idle":"2022-12-01T14:18:25.427502Z","shell.execute_reply.started":"2022-12-01T14:18:23.857167Z","shell.execute_reply":"2022-12-01T14:18:25.426440Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Скачиваем данные","metadata":{"id":"m9XIrxSmW-AX"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"ep1FB3IBW-AY","outputId":"ed833b2b-3b1a-492a-d9a3-ad845a9074c0","execution":{"iopub.status.busy":"2022-12-01T16:25:12.795625Z","iopub.execute_input":"2022-12-01T16:25:12.795987Z","iopub.status.idle":"2022-12-01T16:25:15.914601Z","shell.execute_reply.started":"2022-12-01T16:25:12.795957Z","shell.execute_reply":"2022-12-01T16:25:15.913471Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2022-12-01 16:25:13--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 28717126 (27M) [text/plain]\nSaving to: ‘answers_subsample.csv’\n\nanswers_subsample.c 100%[===================>]  27.39M   174MB/s    in 0.2s    \n\n2022-12-01 16:25:15 (174 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# если ругается на то, что нет wget\n# !apt-get install wget","metadata":{"id":"BWA7IClKW-Aa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"qJpFTPpsW-Ac","outputId":"614d0244-d82c-43fd-c756-c33a3383fa30","execution":{"iopub.status.busy":"2022-12-01T14:18:33.007781Z","iopub.execute_input":"2022-12-01T14:18:33.008175Z","iopub.status.idle":"2022-12-01T14:18:33.953426Z","shell.execute_reply.started":"2022-12-01T14:18:33.008141Z","shell.execute_reply":"2022-12-01T14:18:33.952240Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"total 28052\n---------- 1 root root      263 Dec  1 14:15 __notebook_source__.ipynb\n-rw-r--r-- 1 root root 28717126 Dec  1 14:18 answers_subsample.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"qmzaEwy9W-Ae","execution":{"iopub.status.busy":"2022-12-01T16:25:19.552622Z","iopub.execute_input":"2022-12-01T16:25:19.553894Z","iopub.status.idle":"2022-12-01T16:25:19.559529Z","shell.execute_reply.started":"2022-12-01T16:25:19.553839Z","shell.execute_reply":"2022-12-01T16:25:19.558046Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('answers_subsample.csv')","metadata":{"id":"BbDKxq4EW-Ag","execution":{"iopub.status.busy":"2022-12-01T16:25:20.470162Z","iopub.execute_input":"2022-12-01T16:25:20.470535Z","iopub.status.idle":"2022-12-01T16:25:21.043977Z","shell.execute_reply.started":"2022-12-01T16:25:20.470483Z","shell.execute_reply":"2022-12-01T16:25:21.042985Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"hcAdsbS7W-Ai","outputId":"fe4de523-6803-40cd-ea40-a993217c57d3","execution":{"iopub.status.busy":"2022-12-01T16:25:23.518408Z","iopub.execute_input":"2022-12-01T16:25:23.519338Z","iopub.status.idle":"2022-12-01T16:25:23.541344Z","shell.execute_reply.started":"2022-12-01T16:25:23.519277Z","shell.execute_reply":"2022-12-01T16:25:23.540513Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        category                                               text\n0       business  Могут ли в россельхозбанке дать в залог норков...\n1            law  Может ли срочник перевестись на контракт после...\n2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n3       business  В чем смысл криптовалюты, какая от неё выгода ...\n4            law                 часть 1 статья 158 похитил телефон\n...          ...                                                ...\n237774     relax                                  елку нарядили? =)\n237775       law  Имеется переработка при 75% ставки, отгулы не ...\n237776      food  Попробовала варить рис с половиной кубика для ...\n237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n237778  business  Подскажите какие риски бывают в семье среднест...\n\n[237779 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>business</td>\n      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>law</td>\n      <td>Может ли срочник перевестись на контракт после...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>business</td>\n      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>business</td>\n      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>law</td>\n      <td>часть 1 статья 158 похитил телефон</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237774</th>\n      <td>relax</td>\n      <td>елку нарядили? =)</td>\n    </tr>\n    <tr>\n      <th>237775</th>\n      <td>law</td>\n      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n    </tr>\n    <tr>\n      <th>237776</th>\n      <td>food</td>\n      <td>Попробовала варить рис с половиной кубика для ...</td>\n    </tr>\n    <tr>\n      <th>237777</th>\n      <td>food</td>\n      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n    </tr>\n    <tr>\n      <th>237778</th>\n      <td>business</td>\n      <td>Подскажите какие риски бывают в семье среднест...</td>\n    </tr>\n  </tbody>\n</table>\n<p>237779 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.category.value_counts() * 100 / data.shape[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"id":"90tXLjfsW-Aj","outputId":"5a41f708-1102-49c7-a38f-795783ccdd81","execution":{"iopub.status.busy":"2022-12-01T14:18:52.954744Z","iopub.execute_input":"2022-12-01T14:18:52.955345Z","iopub.status.idle":"2022-12-01T14:18:52.996037Z","shell.execute_reply.started":"2022-12-01T14:18:52.955298Z","shell.execute_reply":"2022-12-01T14:18:52.995085Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"law         29.793211\nrelax       22.016242\nbusiness    19.309527\nfood        18.367055\nlove        10.513965\nName: category, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Предобученные эмбеддинги\n[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \nВы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \nНиже мы сначала скачиваем, а потом распоковываем эмбеддинги.","metadata":{"id":"gfHbifWIW-Al"}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n!gzip -d cc.ru.300.vec.gz","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"PVhCzM3LW-Al","outputId":"7b800ec8-bcad-4859-f110-2ac5ddb07f0e","execution":{"iopub.status.busy":"2022-12-01T14:18:55.558140Z","iopub.execute_input":"2022-12-01T14:18:55.558533Z","iopub.status.idle":"2022-12-01T14:20:07.623662Z","shell.execute_reply.started":"2022-12-01T14:18:55.558497Z","shell.execute_reply":"2022-12-01T14:20:07.622093Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"--2022-12-01 14:18:56--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1306357571 (1.2G) [binary/octet-stream]\nSaving to: ‘cc.ru.300.vec.gz’\n\ncc.ru.300.vec.gz    100%[===================>]   1.22G  36.6MB/s    in 35s     \n\n2022-12-01 14:19:31 (35.9 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -l","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"id":"eJcT1qPZW-An","outputId":"6464b2a1-a04f-4112-a39d-4165ff7c4a79","execution":{"iopub.status.busy":"2022-12-01T14:20:12.440566Z","iopub.execute_input":"2022-12-01T14:20:12.440960Z","iopub.status.idle":"2022-12-01T14:20:13.465725Z","shell.execute_reply.started":"2022-12-01T14:20:12.440927Z","shell.execute_reply":"2022-12-01T14:20:13.464586Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"total 4458144\n---------- 1 root root        263 Dec  1 14:15 __notebook_source__.ipynb\n-rw-r--r-- 1 root root   28717126 Dec  1 14:18 answers_subsample.csv\n-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm import tqdm","metadata":{"id":"M0lwyZUFW-Ap","execution":{"iopub.status.busy":"2022-12-01T14:20:16.076591Z","iopub.execute_input":"2022-12-01T14:20:16.076976Z","iopub.status.idle":"2022-12-01T14:20:16.083191Z","shell.execute_reply.started":"2022-12-01T14:20:16.076944Z","shell.execute_reply":"2022-12-01T14:20:16.081719Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# потом можете добавить свою предобработку\n\ndef process_text(text):\n    \n    words = wordpunct_tokenize(text.lower())\n    \n    return words","metadata":{"id":"QQpX51Y4W-Aq","execution":{"iopub.status.busy":"2022-12-01T14:20:16.923985Z","iopub.execute_input":"2022-12-01T14:20:16.924341Z","iopub.status.idle":"2022-12-01T14:20:16.930008Z","shell.execute_reply.started":"2022-12-01T14:20:16.924309Z","shell.execute_reply":"2022-12-01T14:20:16.928784Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"word2freq = {}\nlengths = []\n\nfor text in tqdm(data.text):\n    \n    words = process_text(text)\n    \n    lengths.append(len(words))\n    \n    for word in words:\n        \n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"HyI2erCDW-Ar","outputId":"0e1fe01d-03f8-4073-b646-53f1a0834d90","execution":{"iopub.status.busy":"2022-12-01T14:20:18.246493Z","iopub.execute_input":"2022-12-01T14:20:18.247625Z","iopub.status.idle":"2022-12-01T14:20:20.424027Z","shell.execute_reply.started":"2022-12-01T14:20:18.247583Z","shell.execute_reply":"2022-12-01T14:20:20.423046Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 237779/237779 [00:02<00:00, 109937.93it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"id":"FGzDm0ptW-At","execution":{"iopub.status.busy":"2022-12-01T14:20:22.862189Z","iopub.execute_input":"2022-12-01T14:20:22.862582Z","iopub.status.idle":"2022-12-01T14:20:23.016932Z","shell.execute_reply.started":"2022-12-01T14:20:22.862546Z","shell.execute_reply":"2022-12-01T14:20:23.016018Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.title('Распределение длин слов в текстах')\nplt.xlabel('Длина предложения')\nplt.ylabel('Доля')\nsns.distplot(lengths)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639},"id":"iZBR-aYDW-Av","outputId":"940b9a8b-91a9-4cdb-f79e-bcd0016e6958","execution":{"iopub.status.busy":"2022-12-01T14:20:23.802209Z","iopub.execute_input":"2022-12-01T14:20:23.802586Z","iopub.status.idle":"2022-12-01T14:20:25.124804Z","shell.execute_reply.started":"2022-12-01T14:20:23.802552Z","shell.execute_reply":"2022-12-01T14:20:25.123770Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:title={'center':'Распределение длин слов в текстах'}, xlabel='Длина предложения', ylabel='Доля'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"upper_threshold = 32\nlower_threshold = 3\n\ncorrect_percent = len([sent_len for sent_len in lengths \n                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n\n'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"OBzmPqXIW-Aw","outputId":"e4430b5f-2d2a-4ac9-fc1a-fa194edd7645","execution":{"iopub.status.busy":"2022-12-01T14:20:44.788170Z","iopub.execute_input":"2022-12-01T14:20:44.788667Z","iopub.status.idle":"2022-12-01T14:20:44.825542Z","shell.execute_reply.started":"2022-12-01T14:20:44.788630Z","shell.execute_reply":"2022-12-01T14:20:44.824392Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"},"metadata":{}}]},{"cell_type":"code","source":"len(word2freq)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"GbSer_0bW-Ay","outputId":"d71619df-f68b-42a8-d851-3c909ceb6370","execution":{"iopub.status.busy":"2022-12-01T14:20:45.797028Z","iopub.execute_input":"2022-12-01T14:20:45.797374Z","iopub.status.idle":"2022-12-01T14:20:45.804314Z","shell.execute_reply.started":"2022-12-01T14:20:45.797343Z","shell.execute_reply":"2022-12-01T14:20:45.803024Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"152179"},"metadata":{}}]},{"cell_type":"code","source":"'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"szg6XD3EW-Az","outputId":"f41121aa-cbb5-426b-b7bb-8f21b1822bd0","execution":{"iopub.status.busy":"2022-12-01T14:20:48.625334Z","iopub.execute_input":"2022-12-01T14:20:48.626045Z","iopub.status.idle":"2022-12-01T14:20:48.673568Z","shell.execute_reply.started":"2022-12-01T14:20:48.626008Z","shell.execute_reply":"2022-12-01T14:20:48.672470Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'114332 слов, которые встречались 3 и менее раз'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Читаем файл с эмбеддингами\n### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\nПоэтому прочитаем только те слова, которые мы знаем","metadata":{"id":"bZbOg0FqW-A1"}},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"T1Yx_qr-W-A2","execution":{"iopub.status.busy":"2022-12-01T14:20:50.923225Z","iopub.execute_input":"2022-12-01T14:20:50.923601Z","iopub.status.idle":"2022-12-01T14:20:50.928064Z","shell.execute_reply.started":"2022-12-01T14:20:50.923568Z","shell.execute_reply":"2022-12-01T14:20:50.927107Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('cc.ru.300.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"BLEgfnaWW-A4","outputId":"05846f70-6229-4df2-bcd5-68cc08e0d010","execution":{"iopub.status.busy":"2022-12-01T14:20:54.179944Z","iopub.execute_input":"2022-12-01T14:20:54.180333Z","iopub.status.idle":"2022-12-01T14:21:59.515444Z","shell.execute_reply.started":"2022-12-01T14:20:54.180299Z","shell.execute_reply":"2022-12-01T14:21:59.514382Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Read word2vec: 100%|██████████| 2000000/2000000 [01:04<00:00, 30842.46it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(word2index)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"AYJMzgpnW-A7","outputId":"4fec5db6-fca6-42a2-93da-be988702d797","execution":{"iopub.status.busy":"2022-12-01T14:22:23.646136Z","iopub.execute_input":"2022-12-01T14:22:23.646559Z","iopub.status.idle":"2022-12-01T14:22:23.652990Z","shell.execute_reply.started":"2022-12-01T14:22:23.646523Z","shell.execute_reply":"2022-12-01T14:22:23.652058Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"117619"},"metadata":{}}]},{"cell_type":"code","source":"unk_words = [word for word in word2freq if word not in word2index]\nunk_counts = [word2freq[word] for word in unk_words]\nn_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n\nsub_sample_unk_words = {word: word2freq[word] for word in unk_words}\nsorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n\nprint('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\nprint('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\nprint('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\nprint()\nprint('Топ 5 невошедших слов:')\n\nfor i in range(5):\n    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"KE06fafiW-A8","outputId":"d6c87428-4474-4275-f300-d246364d7865","execution":{"iopub.status.busy":"2022-12-01T14:22:24.519911Z","iopub.execute_input":"2022-12-01T14:22:24.520996Z","iopub.status.idle":"2022-12-01T14:22:24.607595Z","shell.execute_reply.started":"2022-12-01T14:22:24.520947Z","shell.execute_reply":"2022-12-01T14:22:24.606466Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Мы не знаем 2.50 % слов в датасете\nКоличество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\nВ среднем каждое встречается 1.98 раз\n\nТоп 5 невошедших слов:\n??? с количеством вхождениий - 3641\n?? с количеством вхождениий - 2448\n!!! с количеством вхождениий - 2214\n?) с количеством вхождениий - 2069\n\"? с количеством вхождениий - 1429\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Потеря 2.5 % слов в датасете\nЭта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой.","metadata":{"id":"GFPNApUjW-A9"}},{"cell_type":"code","source":"import torch","metadata":{"id":"_fo1fB6JW-A-","execution":{"iopub.status.busy":"2022-12-01T14:22:27.574131Z","iopub.execute_input":"2022-12-01T14:22:27.574551Z","iopub.status.idle":"2022-12-01T14:22:29.360185Z","shell.execute_reply.started":"2022-12-01T14:22:27.574517Z","shell.execute_reply":"2022-12-01T14:22:29.359099Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"pEKAjCg3W-BA"}},{"cell_type":"code","source":"x = torch.rand(128, 64, 1024)","metadata":{"id":"D19pDyQBW-BA","execution":{"iopub.status.busy":"2022-12-01T14:22:31.818069Z","iopub.execute_input":"2022-12-01T14:22:31.818853Z","iopub.status.idle":"2022-12-01T14:22:31.887026Z","shell.execute_reply.started":"2022-12-01T14:22:31.818814Z","shell.execute_reply":"2022-12-01T14:22:31.886114Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512, batch_first=True)","metadata":{"id":"Yxsxr7edW-BB","execution":{"iopub.status.busy":"2022-12-01T14:22:32.686363Z","iopub.execute_input":"2022-12-01T14:22:32.687207Z","iopub.status.idle":"2022-12-01T14:22:32.734731Z","shell.execute_reply.started":"2022-12-01T14:22:32.687166Z","shell.execute_reply":"2022-12-01T14:22:32.733878Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm(x)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"TZy0lKr2W-BC","outputId":"4556ff61-4bd7-4ba5-da18-a26410a64d25","execution":{"iopub.status.busy":"2022-12-01T14:22:33.611872Z","iopub.execute_input":"2022-12-01T14:22:33.612228Z","iopub.status.idle":"2022-12-01T14:22:37.531443Z","shell.execute_reply.started":"2022-12-01T14:22:33.612196Z","shell.execute_reply":"2022-12-01T14:22:37.530251Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"481 ms ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# А что GPU?","metadata":{"id":"s611e34SW-BE"}},{"cell_type":"code","source":"print('Доступна ли видеокарта:', torch.cuda.is_available())\nprint('Если недоступна, поменяйте runtime, если в колабе')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"xjFlWdgtW-BE","outputId":"93205b98-fd2b-4bea-a93f-5544f82c5a2c","execution":{"iopub.status.busy":"2022-12-01T14:22:40.420218Z","iopub.execute_input":"2022-12-01T14:22:40.420912Z","iopub.status.idle":"2022-12-01T14:22:40.492847Z","shell.execute_reply.started":"2022-12-01T14:22:40.420875Z","shell.execute_reply":"2022-12-01T14:22:40.491895Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Доступна ли видеокарта: True\nЕсли недоступна, поменяйте runtime, если в колабе\n","output_type":"stream"}]},{"cell_type":"code","source":"# универсальных способ задать device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать","metadata":{"id":"jaMMD5CDW-BG","execution":{"iopub.status.busy":"2022-12-01T14:22:44.686452Z","iopub.execute_input":"2022-12-01T14:22:44.687101Z","iopub.status.idle":"2022-12-01T14:22:44.693541Z","shell.execute_reply.started":"2022-12-01T14:22:44.687064Z","shell.execute_reply":"2022-12-01T14:22:44.692454Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# перенесли x на gpu\nx_gpu = x.to(device)","metadata":{"id":"GeQCiSYdW-BH","execution":{"iopub.status.busy":"2022-12-01T14:22:48.434504Z","iopub.execute_input":"2022-12-01T14:22:48.436716Z","iopub.status.idle":"2022-12-01T14:22:51.116277Z","shell.execute_reply.started":"2022-12-01T14:22:48.436667Z","shell.execute_reply":"2022-12-01T14:22:51.115243Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# зададим lstm на gpu\nlstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\nlstm_gpu = lstm_gpu.to(device)","metadata":{"id":"S_qUdMcbW-BJ","execution":{"iopub.status.busy":"2022-12-01T14:22:53.936909Z","iopub.execute_input":"2022-12-01T14:22:53.938044Z","iopub.status.idle":"2022-12-01T14:22:54.749633Z","shell.execute_reply.started":"2022-12-01T14:22:53.937992Z","shell.execute_reply":"2022-12-01T14:22:54.748624Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm_gpu(x_gpu)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"hSUQmRgtW-BK","outputId":"44da2f5b-6421-44d9-829b-499212280ee1","execution":{"iopub.status.busy":"2022-12-01T14:22:56.096751Z","iopub.execute_input":"2022-12-01T14:22:56.097122Z","iopub.status.idle":"2022-12-01T14:23:03.968412Z","shell.execute_reply.started":"2022-12-01T14:22:56.097091Z","shell.execute_reply":"2022-12-01T14:23:03.967475Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"9.97 ms ± 7.45 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз","metadata":{"id":"gPvqNWkQW-BM"}},{"cell_type":"code","source":"# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n# справедлива и обратная ситуация\n\n# выскочит ошибка\n# посмотрите на нее, возможно, вы еще встретитесь\n# pred = lstm_gpu(x)","metadata":{"id":"FaPKGO5aW-BN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Важные и не очень интуитивные моменты про LSTM и CNN в торче","metadata":{"id":"9NX5HHDOW-BO"}},{"cell_type":"markdown","source":"По умолчанию LSTM принимает данные с такой размерностью:\n```python\n(seq_len, batch, input_size)\n```\nСделано это с целью оптимизации на более низком уровне.  \nМы оперируем такими объектами:\n```python\n(batch, seq_len, input_size)\n```\nЧтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\nлибо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)","metadata":{"id":"zKr22rklW-BP"}},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"Bny8SvCgW-BQ"}},{"cell_type":"code","source":"# первый способ\nlstm = torch.nn.LSTM(1024, 512, batch_first=True)\n\npred, mem = lstm(x)","metadata":{"id":"vc-bLok2W-BQ"},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"OHpit-1tW-BR","outputId":"e33f0f23-f029-4e7b-b1ff-d3b12276db82"},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 64, 512])"]},"metadata":{}}]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512)\n\n# меняем размерность batch и seq_len местами\nx_transposed = x.transpose(0, 1)\npred_transposed, mem = lstm(x_transposed)","metadata":{"id":"ru_WzGSJW-BS"},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# у нас все еще осталась размерность (seq_len, batch, input_size)\npred_transposed.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"NHdBavTWW-BT","outputId":"ba454a8b-fec7-402f-a7a1-c4f9f9556e6d"},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 128, 512])"]},"metadata":{}}]},{"cell_type":"code","source":"# просто транспонируем еще раз\npred = pred_transposed.transpose(0, 1)\npred.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"Rcxv55j7W-BV","outputId":"f560450f-75bf-4397-d9f0-f88e3d06705c"},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 64, 512])"]},"metadata":{}}]},{"cell_type":"markdown","source":"## Conv1d & MaxPool1d\nПримерно такая же ситуация происходит со сверточными слоями и пулингами.  \n1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \nОжидается такая размерность:\n```python\n(batch, input_size, seq_len)\n```\nМы все еще хоти подавать такую размерность:\n```python\n(batch, seq_len, input_size)\n```\nВ случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля).","metadata":{"id":"PmJt6cqkW-BW"}},{"cell_type":"code","source":"x.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"TyM8Xl24W-BX","outputId":"2a5512ca-bc14-43f1-804b-e71df3a7ad7e"},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 32])"]},"metadata":{}}]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"grPNMjEZW-BY"}},{"cell_type":"code","source":"# in_channels - размер входных эмбеддингов\n# out_channels - количество/какой размер эмбеддингов мы хотим получить\n# kernel_size - размер окна/н-граммы\ncnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)","metadata":{"id":"btJ-ApiOW-BY"},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# выпадет ошибка, посмотрите какая\n# pred = cnn(x)","metadata":{"id":"QIYff7YyW-Bb"},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"x_transposed = x.transpose(1, 2)\nx_transposed.shape\n# перевели в (batch, input_size, seq_len)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"7tVn6YKLW-Bd","outputId":"7a1a5f4c-b44f-4ed6-f90c-a9d00f78dfe6"},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 1024, 64])"]},"metadata":{}}]},{"cell_type":"code","source":"pred_transposed = cnn(x_transposed)\npred_transposed.shape\n# осталась разрмерность (batch, output_size, seq_len)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"2N4w6-iWW-Be","outputId":"bf29af13-5bd4-4882-f60f-b01575b100e8"},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 512, 62])"]},"metadata":{}}]},{"cell_type":"code","source":"# переведем обратно в (batch, seq_len, input_size)\npred = pred_transposed.transpose(1, 2)\npred.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"7-C3_phaW-Bf","outputId":"2ce7a78f-5492-404a-aeb5-2911386734d4"},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 62, 512])"]},"metadata":{}}]},{"cell_type":"markdown","source":"# Подготовим данные в DataLoader","metadata":{"id":"stBQ3yhqW-Bi"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"id":"vPX_m5M4W-Bi","execution":{"iopub.status.busy":"2022-12-01T14:23:44.575028Z","iopub.execute_input":"2022-12-01T14:23:44.575440Z","iopub.status.idle":"2022-12-01T14:23:44.580753Z","shell.execute_reply.started":"2022-12-01T14:23:44.575385Z","shell.execute_reply":"2022-12-01T14:23:44.579131Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"'UNK' in word2index","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"hV76BdN0W-Bj","outputId":"befb4dd0-0df1-4ada-fe1d-dae478226f35","execution":{"iopub.status.busy":"2022-12-01T14:23:45.559770Z","iopub.execute_input":"2022-12-01T14:23:45.560161Z","iopub.status.idle":"2022-12-01T14:23:45.567526Z","shell.execute_reply.started":"2022-12-01T14:23:45.560118Z","shell.execute_reply":"2022-12-01T14:23:45.566323Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"INB_dPAnW-Bk","outputId":"8bb90efa-4c9c-4908-c872-393906ed8619","execution":{"iopub.status.busy":"2022-12-01T14:23:46.343802Z","iopub.execute_input":"2022-12-01T14:23:46.344531Z","iopub.status.idle":"2022-12-01T14:23:46.354465Z","shell.execute_reply.started":"2022-12-01T14:23:46.344492Z","shell.execute_reply":"2022-12-01T14:23:46.353468Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   category                                               text\n0  business  Могут ли в россельхозбанке дать в залог норков...\n1       law  Может ли срочник перевестись на контракт после...\n2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n3  business  В чем смысл криптовалюты, какая от неё выгода ...\n4       law                 часть 1 статья 158 похитил телефон","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>business</td>\n      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>law</td>\n      <td>Может ли срочник перевестись на контракт после...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>business</td>\n      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>business</td>\n      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>law</td>\n      <td>часть 1 статья 158 похитил телефон</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Замапим категории в индексы","metadata":{"id":"1qv1mKAeW-Bl"}},{"cell_type":"code","source":"cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}","metadata":{"id":"iHeFzZe1W-Bl","execution":{"iopub.status.busy":"2022-12-01T14:23:48.884148Z","iopub.execute_input":"2022-12-01T14:23:48.884534Z","iopub.status.idle":"2022-12-01T14:23:48.907010Z","shell.execute_reply.started":"2022-12-01T14:23:48.884500Z","shell.execute_reply":"2022-12-01T14:23:48.905984Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"cat_mapper","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"X3x9QhXYW-Bn","outputId":"0a4dff58-d739-4847-f818-c3e0d321e78a","execution":{"iopub.status.busy":"2022-12-01T14:23:55.371752Z","iopub.execute_input":"2022-12-01T14:23:55.372130Z","iopub.status.idle":"2022-12-01T14:23:55.380277Z","shell.execute_reply.started":"2022-12-01T14:23:55.372098Z","shell.execute_reply":"2022-12-01T14:23:55.379150Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"},"metadata":{}}]},{"cell_type":"code","source":"data.category = data.category.map(cat_mapper)","metadata":{"id":"ef--8SWbW-Bo","execution":{"iopub.status.busy":"2022-12-01T14:23:56.492684Z","iopub.execute_input":"2022-12-01T14:23:56.493044Z","iopub.status.idle":"2022-12-01T14:23:56.513063Z","shell.execute_reply.started":"2022-12-01T14:23:56.493013Z","shell.execute_reply":"2022-12-01T14:23:56.512071Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Читалка данных","metadata":{"id":"vc48ALg_W-Bp"}},{"cell_type":"markdown","source":"## Что происходит ниже\n1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n1. Загружаем данные:\n    1. Проходимся по датасету\n    1. Предобрабатываем каждый текст в датасете\n    1. Индексируем его\n    1. Паддим до нужной длины\n1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n","metadata":{"id":"WFIQEv6nvE4c"}},{"cell_type":"code","source":"class WordData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.sequence_length = sequence_length\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text):\n        \n        # Место для вашей предобработки\n        \n        words = wordpunct_tokenize(text.lower())\n        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            \n            words = self.process_text(text)\n            indexed_words = self.indexing(words)\n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n\n        # здесь мы не используем токен UNK, потому что мы его специально не учили\n        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n        # поэтому просто выбрасываем наши неизветсные слова\n        \n        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n        if len(sequence)< self.sequence_length:\n            add_pad = self.sequence_length - len(sequence)\n            return sequence+[self.pad_index]*add_pad\n        else:\n            return sequence[:self.sequence_length]\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()\n        \n        y = self.y_data[idx]\n        \n        return x, y","metadata":{"id":"ZkX8SC_sW-Bp","execution":{"iopub.status.busy":"2022-12-01T14:23:59.466594Z","iopub.execute_input":"2022-12-01T14:23:59.466959Z","iopub.status.idle":"2022-12-01T14:23:59.480894Z","shell.execute_reply.started":"2022-12-01T14:23:59.466930Z","shell.execute_reply":"2022-12-01T14:23:59.479655Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"id":"R3WW8V9lyLm0","execution":{"iopub.status.busy":"2022-12-01T14:24:03.248691Z","iopub.execute_input":"2022-12-01T14:24:03.249506Z","iopub.status.idle":"2022-12-01T14:24:03.254358Z","shell.execute_reply.started":"2022-12-01T14:24:03.249467Z","shell.execute_reply":"2022-12-01T14:24:03.253269Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n\ntrain_dataset = WordData(list(x_train), list(y_train), word2index)\ntrain_loader = DataLoader(train_dataset, batch_size=64)\n\nvalidation_dataset = WordData(list(x_validation), list(y_validation), word2index)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"Lnc2nD8gW-Br","outputId":"d72654f9-7a85-49a6-e0c2-429b5db04c4e","execution":{"iopub.status.busy":"2022-12-01T14:24:06.528932Z","iopub.execute_input":"2022-12-01T14:24:06.529888Z","iopub.status.idle":"2022-12-01T14:24:09.543148Z","shell.execute_reply.started":"2022-12-01T14:24:06.529834Z","shell.execute_reply":"2022-12-01T14:24:09.542148Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Loading data: 100%|██████████| 214001/214001 [00:02<00:00, 79954.65it/s] \nLoading data: 100%|██████████| 23778/23778 [00:00<00:00, 104321.58it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for x, y in train_loader:\n    break","metadata":{"id":"dGeftxdgW-Br","execution":{"iopub.status.busy":"2022-12-01T14:24:12.316886Z","iopub.execute_input":"2022-12-01T14:24:12.317253Z","iopub.status.idle":"2022-12-01T14:24:12.325225Z","shell.execute_reply.started":"2022-12-01T14:24:12.317221Z","shell.execute_reply":"2022-12-01T14:24:12.324221Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"nNkGQffBW-Bs","outputId":"77e1ecb5-4bdc-414d-fb89-b7650ed25fba","execution":{"iopub.status.busy":"2022-12-01T14:24:13.298712Z","iopub.execute_input":"2022-12-01T14:24:13.299086Z","iopub.status.idle":"2022-12-01T14:24:13.308291Z","shell.execute_reply.started":"2022-12-01T14:24:13.299053Z","shell.execute_reply":"2022-12-01T14:24:13.307237Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"tensor([[ 7758,     2, 12814,  ...,     0,     0,     0],\n        [64260,     0,     0,  ...,     0,     0,     0],\n        [24366,   667,     8,  ...,     0,     0,     0],\n        ...,\n        [ 2819, 41212,     1,  ...,     0,     0,     0],\n        [   65,   137, 25473,  ...,     0,     0,     0],\n        [ 4316,     8, 11253,  ...,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"fxUk4nGcW-Bt","outputId":"bae977fd-25ef-4fd7-c451-402e8ea287a4","execution":{"iopub.status.busy":"2022-12-01T14:24:16.079152Z","iopub.execute_input":"2022-12-01T14:24:16.079975Z","iopub.status.idle":"2022-12-01T14:24:16.088468Z","shell.execute_reply.started":"2022-12-01T14:24:16.079926Z","shell.execute_reply":"2022-12-01T14:24:16.087311Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"tensor([1, 4, 1, 1, 0, 3, 1, 3, 0, 3, 2, 0, 0, 4, 3, 4, 1, 4, 2, 1, 4, 0, 4, 2,\n        0, 0, 0, 4, 4, 3, 4, 4, 0, 4, 4, 0, 1, 2, 4, 0, 1, 3, 3, 4, 3, 1, 3, 2,\n        3, 0, 3, 1, 3, 1, 1, 3, 1, 3, 1, 2, 1, 1, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"y.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T14:24:16.804695Z","iopub.execute_input":"2022-12-01T14:24:16.805057Z","iopub.status.idle":"2022-12-01T14:24:16.811543Z","shell.execute_reply.started":"2022-12-01T14:24:16.805028Z","shell.execute_reply":"2022-12-01T14:24:16.810460Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Обучить нейронку","metadata":{"id":"Zy0dkkTIW-Bw"}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_with_att(torch.nn.Module):\n    def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n\n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256 ,num_layers=2, bidirectional=True, batch_first=True, dropout=0.1)\n        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,))# три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n        self.relu = torch.nn.ReLU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=n, bias=True)\n\n        \n    def forward(self, x):\n        x_emb = self.emb_layer(x) #примените эмбеддинги\n        # транспонируйте тензор для лстм как было описано выше\n        x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n        # транспонируйте обратно\n\n        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n        x_k = self.k_proj(x)\n        x_v = self.v_proj(x)\n        \n        att_scores = torch.bmm(x_q, x_k.transpose(1, 2))/(x_k.transpose(1, 2).shape[0])**0.5\n        # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n        # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n        attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :\n\n        x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n        x_cnn3 = self.cnn_3gr(x_att)\n        x_cnn4 = self.cnn_4gr(x_att)\n        x_cnn5 = self.cnn_5gr(x_att)\n\n        frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n        sc, _ = x_cnn4.max(dim= -1,)\n        thr, _ = x_cnn5.max(dim= -1,)\n\n        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n\n        x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n        x = self.relu(x)    \n        x = self.linear_2(x)\n\n        return x","metadata":{"id":"3wwkxZm1vE43"},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"n_classes = data.category.unique().shape[0]","metadata":{"id":"jFbyUXLE0WPv","execution":{"iopub.status.busy":"2022-12-01T14:24:22.133013Z","iopub.execute_input":"2022-12-01T14:24:22.133384Z","iopub.status.idle":"2022-12-01T14:24:22.141315Z","shell.execute_reply.started":"2022-12-01T14:24:22.133351Z","shell.execute_reply":"2022-12-01T14:24:22.140164Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = model_with_att(vectors, n_classes)","metadata":{"id":"OZgh4ONx0HvT"},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# model #если сделать batch_first=True, то можно не транспонировать батчи","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"CNO6VSbJgQ36","outputId":"409a1cc5-8448-4a0e-ec43-77d8d6f79683"},"execution_count":null,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":["model_with_att(\n","  (emb_layer): Embedding(117619, 300)\n","  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n","  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n","  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n","  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n","  (att_soft): Softmax(dim=2)\n","  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n","  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n","  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n","  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n","  (relu): ReLU()\n","  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]}}]},{"cell_type":"code","source":"with torch.no_grad():\n    pred = model(x)","metadata":{"id":"E66MWNgM0QKM"},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"ErboeQbv0dnC"},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 5])"]},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"bL6zIZSt0h9W"},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"id":"Vsxw4M2m0m2B"},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"7rUTc0l60pV9","outputId":"ea81b9b3-b1d3-4122-869b-da0592397d76"},"execution_count":133,"outputs":[{"name":"stderr","output_type":"stream","text":"Epoch 1: 100%|████████████████████████████████████████| 214001/214001 [31:13<00:00, 114.23it/s, train_loss=0.479]\n"},{"name":"stdout","output_type":"stream","text":"\n\nLosses: train - 0.558, test - 0.467\n\nF1 test - 0.832\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2: 100%|████████████████████████████████████████| 214001/214001 [34:31<00:00, 103.29it/s, train_loss=0.444]\n"},{"name":"stdout","output_type":"stream","text":"\n\nLosses: train - 0.455, test - 0.448\n\nF1 test - 0.840\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3: 100%|█████████████████████████████████████████| 214001/214001 [34:10<00:00, 104.35it/s, train_loss=0.42]\n"},{"name":"stdout","output_type":"stream","text":"\n\nLosses: train - 0.427, test - 0.439\n\nF1 test - 0.844\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4: 100%|████████████████████████████████████████| 214001/214001 [27:57<00:00, 127.53it/s, train_loss=0.397]\n"},{"name":"stdout","output_type":"stream","text":"\n\nLosses: train - 0.405, test - 0.439\n\nF1 test - 0.844\n\nEarly stopping\n"}]},{"cell_type":"markdown","source":"Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо","metadata":{"id":"1TMaPbh3oWwc"}},{"cell_type":"code","source":"for instance in list(tqdm._instances): \n    tqdm._decr_instances(instance)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"_aPjTQcR0vm2","outputId":"03d584f8-2f8c-4e0b-ae8e-7112f6624275","execution":{"iopub.status.busy":"2022-12-01T15:03:35.241504Z","iopub.execute_input":"2022-12-01T15:03:35.241885Z","iopub.status.idle":"2022-12-01T15:03:35.246817Z","shell.execute_reply.started":"2022-12-01T15:03:35.241839Z","shell.execute_reply":"2022-12-01T15:03:35.245712Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"# Оценка\n1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов ","metadata":{}},{"cell_type":"markdown","source":"## Эксперименты","metadata":{"id":"e5BgHdtW2sO3"}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_with_att(torch.nn.Module):\n    def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n\n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256 ,num_layers=2, bidirectional=True, batch_first=True)\n        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_2gr = torch.nn.Conv1d(256, 128, kernel_size=(2,), stride=(1,))# три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n        self.cnn_6gr = torch.nn.Conv1d(256, 128, kernel_size=(6,), stride=(1,))\n        \n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n        self.gelu = torch.nn.GELU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=n, bias=True)\n\n        \n    def forward(self, x):\n        x_emb = self.emb_layer(x) #примените эмбеддинги\n        # транспонируйте тензор для лстм как было описано выше\n        x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n        # транспонируйте обратно\n\n        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n        x_k = self.k_proj(x)\n        x_v = self.v_proj(x)\n        \n        att_scores = torch.bmm(x_q, x_k.transpose(1, 2))/(x_k.transpose(1, 2).shape[0])**0.5\n        # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n        # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n        attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :\n\n        x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n        x_cnn2 = self.cnn_2gr(x_att)\n        x_cnn3 = self.cnn_3gr(x_att)\n        x_cnn4 = self.cnn_4gr(x_att)\n        \n\n        frst, _ =  x_cnn2.max(dim= -1,) # cделаем макс пуллинг\n        sc, _ = x_cnn3.max(dim= -1,)\n        thr, _ = x_cnn4.max(dim= -1,)\n\n        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n\n        x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n        x = self.gelu(x)    \n        x = self.linear_2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:03:28.344451Z","iopub.execute_input":"2022-12-01T15:03:28.344814Z","iopub.status.idle":"2022-12-01T15:03:28.361729Z","shell.execute_reply.started":"2022-12-01T15:03:28.344781Z","shell.execute_reply":"2022-12-01T15:03:28.360659Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"Epoch 1:  29%|██▉       | 62144/214001 [00:29<00:41, 3635.64it/s, train_loss=0.552]","output_type":"stream"}]},{"cell_type":"code","source":"model = model_with_att(vectors, n_classes)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:03:43.197506Z","iopub.execute_input":"2022-12-01T15:03:43.197995Z","iopub.status.idle":"2022-12-01T15:03:43.421888Z","shell.execute_reply.started":"2022-12-01T15:03:43.197954Z","shell.execute_reply":"2022-12-01T15:03:43.420463Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"model_with_att(\n  (emb_layer): Embedding(117619, 300)\n  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, bidirectional=True)\n  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n  (att_soft): Softmax(dim=2)\n  (cnn_2gr): Conv1d(256, 128, kernel_size=(2,), stride=(1,))\n  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n  (gelu): GELU()\n  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)\n\nepochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:03:48.009440Z","iopub.execute_input":"2022-12-01T15:03:48.009789Z","iopub.status.idle":"2022-12-01T15:07:57.133434Z","shell.execute_reply.started":"2022-12-01T15:03:48.009758Z","shell.execute_reply":"2022-12-01T15:07:57.132463Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 214001/214001 [01:00<00:00, 3563.15it/s, train_loss=0.474]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.567, test - 0.463\nF1 test - 0.833\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 214001/214001 [01:00<00:00, 3561.43it/s, train_loss=0.439]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.451, test - 0.452\nF1 test - 0.837\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 214001/214001 [01:00<00:00, 3544.68it/s, train_loss=0.415]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.424, test - 0.445\nF1 test - 0.841\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 214001/214001 [01:00<00:00, 3551.91it/s, train_loss=0.391]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.400, test - 0.446\nF1 test - 0.842\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Что я попробовала:**\n- увеличить количество слоев в лсм до трех (и дропаут до 0.2) \n- оставить 1-2 слоя в лстм, но убрать дропаут\n- поменять параметры сверточных фильтров на: (2, 3, 4), (2, 4, 6), (2, 3, 4, 6)\n- увеличить количество линейных преобразований после сверток до 4-х  и вставить между ними GELU (каждый следующий слой понижал размерность в два раза относительно предыдущего)\n\n(и некоторые комбинации этих изменений)\n\nПочти все эти преобразования (кроме второго) были продиктованы предположением о том, что более сложная модель имеет более низкое смещение относительно простой и сможет лучше выучивать сложные зависимости, однако ни одно из изменений не повысило скор, максимальный результат - 0.842","metadata":{}},{"cell_type":"markdown","source":"## Вариация на тему бертовой тетрадки\n\nМне стало интересно сравнить скоры модели из домашки и берта на том же датасете, поэтому ниже я попробую дообучить берт под эту задачу, но с некоторым упрощением - без кастомного training-loop'a, а через трансформеровский trainer ","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:55:01.171415Z","iopub.execute_input":"2022-12-01T16:55:01.171826Z","iopub.status.idle":"2022-12-01T16:55:01.197719Z","shell.execute_reply.started":"2022-12-01T16:55:01.171744Z","shell.execute_reply":"2022-12-01T16:55:01.196857Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:55:02.366375Z","iopub.execute_input":"2022-12-01T16:55:02.366714Z","iopub.status.idle":"2022-12-01T16:55:04.408562Z","shell.execute_reply.started":"2022-12-01T16:55:02.366685Z","shell.execute_reply":"2022-12-01T16:55:04.407562Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install evaluate","metadata":{"execution":{"iopub.status.idle":"2022-12-01T16:55:24.806327Z","shell.execute_reply.started":"2022-12-01T16:55:13.643738Z","shell.execute_reply":"2022-12-01T16:55:24.805070Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Installing collected packages: evaluate\nSuccessfully installed evaluate-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport evaluate\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:55:26.880286Z","iopub.execute_input":"2022-12-01T16:55:26.880838Z","iopub.status.idle":"2022-12-01T16:55:35.897525Z","shell.execute_reply.started":"2022-12-01T16:55:26.880799Z","shell.execute_reply":"2022-12-01T16:55:35.896407Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"vals = data[data.columns[0]]\ncl = pd.get_dummies(vals)\ncl = cl.astype('float')\ncl","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:55:52.058349Z","iopub.execute_input":"2022-12-01T16:55:52.059990Z","iopub.status.idle":"2022-12-01T16:55:52.122007Z","shell.execute_reply.started":"2022-12-01T16:55:52.059951Z","shell.execute_reply":"2022-12-01T16:55:52.121118Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        business  food  law  love  relax\n0            1.0   0.0  0.0   0.0    0.0\n1            0.0   0.0  1.0   0.0    0.0\n2            1.0   0.0  0.0   0.0    0.0\n3            1.0   0.0  0.0   0.0    0.0\n4            0.0   0.0  1.0   0.0    0.0\n...          ...   ...  ...   ...    ...\n237774       0.0   0.0  0.0   0.0    1.0\n237775       0.0   0.0  1.0   0.0    0.0\n237776       0.0   1.0  0.0   0.0    0.0\n237777       0.0   1.0  0.0   0.0    0.0\n237778       1.0   0.0  0.0   0.0    0.0\n\n[237779 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business</th>\n      <th>food</th>\n      <th>law</th>\n      <th>love</th>\n      <th>relax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237774</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>237775</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>237776</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>237777</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>237778</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>237779 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"text = data['text'].tolist()\nlabels = cl.values","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:55:55.606084Z","iopub.execute_input":"2022-12-01T16:55:55.606954Z","iopub.status.idle":"2022-12-01T16:55:55.635006Z","shell.execute_reply.started":"2022-12-01T16:55:55.606919Z","shell.execute_reply":"2022-12-01T16:55:55.633870Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/ruBert-base')\nmodel = AutoModelForSequenceClassification.from_pretrained('sberbank-ai/ruBert-base', num_labels = 5)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:56:26.865489Z","iopub.execute_input":"2022-12-01T16:56:26.865848Z","iopub.status.idle":"2022-12-01T16:57:06.993321Z","shell.execute_reply.started":"2022-12-01T16:56:26.865817Z","shell.execute_reply":"2022-12-01T16:57:06.992392Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/590 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4b66146d2541bfbb1225e11f71554b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.70M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8690b5eea164715bafb9842548cb235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/683M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4975b8eb451446eb84d2784998d73c66"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at sberbank-ai/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# я посмотрела, что вся модель будет учиться несколько часов, поэтому решила частично зафризить\n\nnames = []\nfor name, param in model.named_parameters():\n\tnames.append(name)\nlen(names)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:09.960406Z","iopub.execute_input":"2022-12-01T16:57:09.960760Z","iopub.status.idle":"2022-12-01T16:57:09.971371Z","shell.execute_reply.started":"2022-12-01T16:57:09.960730Z","shell.execute_reply":"2022-12-01T16:57:09.970350Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"201"},"metadata":{}}]},{"cell_type":"code","source":"cut_lrs = names[:100]\nfor name, param in model.named_parameters():\n    if name in cut_lrs: \n        param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:24.133099Z","iopub.execute_input":"2022-12-01T16:57:24.133715Z","iopub.status.idle":"2022-12-01T16:57:24.139820Z","shell.execute_reply.started":"2022-12-01T16:57:24.133681Z","shell.execute_reply":"2022-12-01T16:57:24.138895Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"labels = torch.tensor(labels)\nX_train, X_test, y_train, y_test = train_test_split(text, labels, test_size = 0.33, random_state=666, shuffle=True )","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:26.697925Z","iopub.execute_input":"2022-12-01T16:57:26.698302Z","iopub.status.idle":"2022-12-01T16:57:26.789201Z","shell.execute_reply.started":"2022-12-01T16:57:26.698271Z","shell.execute_reply":"2022-12-01T16:57:26.788197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def prep(text, tokenizer=tokenizer):\n    return tokenizer(text, padding = 'max_length', max_length = 128, truncation=True, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:27.702393Z","iopub.execute_input":"2022-12-01T16:57:27.702751Z","iopub.status.idle":"2022-12-01T16:57:27.707819Z","shell.execute_reply.started":"2022-12-01T16:57:27.702721Z","shell.execute_reply":"2022-12-01T16:57:27.706714Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train = prep(X_train)\nX_test = prep(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:28.700478Z","iopub.execute_input":"2022-12-01T16:57:28.700840Z","iopub.status.idle":"2022-12-01T16:57:56.060163Z","shell.execute_reply.started":"2022-12-01T16:57:28.700810Z","shell.execute_reply":"2022-12-01T16:57:56.059189Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class TextDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = torch.tensor(labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = TextDataset(X_train, y_train)\nval_dataset = TextDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:57:58.616347Z","iopub.execute_input":"2022-12-01T16:57:58.616781Z","iopub.status.idle":"2022-12-01T16:57:58.626947Z","shell.execute_reply.started":"2022-12-01T16:57:58.616748Z","shell.execute_reply":"2022-12-01T16:57:58.625760Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  after removing the cwd from sys.path.\n","output_type":"stream"}]},{"cell_type":"code","source":"metric = evaluate.load(\"f1\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:58:01.423826Z","iopub.execute_input":"2022-12-01T16:58:01.424211Z","iopub.status.idle":"2022-12-01T16:58:02.569587Z","shell.execute_reply.started":"2022-12-01T16:58:01.424177Z","shell.execute_reply":"2022-12-01T16:58:02.568720Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15665553c4304b5a98afb5b4c991dffb"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=[np.argmax(i, axis=-1) for i in labels], average='micro')","metadata":{"execution":{"iopub.status.busy":"2022-12-01T17:32:25.819528Z","iopub.execute_input":"2022-12-01T17:32:25.819884Z","iopub.status.idle":"2022-12-01T17:32:25.827314Z","shell.execute_reply.started":"2022-12-01T17:32:25.819853Z","shell.execute_reply":"2022-12-01T17:32:25.826375Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir=\"./hw2_rubert\",\n                                  evaluation_strategy=\"epoch\",\n                                  per_device_train_batch_size = 64,\n                                  per_device_eval_batch_size = 64,\n                                  save_strategy = 'epoch',\n                                  num_train_epochs=4)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T17:32:32.362226Z","iopub.execute_input":"2022-12-01T17:32:32.362580Z","iopub.status.idle":"2022-12-01T17:32:32.375364Z","shell.execute_reply.started":"2022-12-01T17:32:32.362551Z","shell.execute_reply":"2022-12-01T17:32:32.374008Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T17:32:34.254413Z","iopub.execute_input":"2022-12-01T17:32:34.254769Z","iopub.status.idle":"2022-12-01T17:32:34.272245Z","shell.execute_reply.started":"2022-12-01T17:32:34.254740Z","shell.execute_reply":"2022-12-01T17:32:34.271219Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T17:32:37.228112Z","iopub.execute_input":"2022-12-01T17:32:37.230552Z","iopub.status.idle":"2022-12-01T18:21:15.794975Z","shell.execute_reply.started":"2022-12-01T17:32:37.230517Z","shell.execute_reply":"2022-12-01T18:21:15.793115Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 159311\n  Num Epochs = 4\n  Instantaneous batch size per device = 64\n  Total train batch size (w. parallel, distributed & accumulation) = 64\n  Gradient Accumulation steps = 1\n  Total optimization steps = 9960\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5034' max='9960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5034/9960 48:37 < 47:36, 1.72 it/s, Epoch 2.02/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.135400</td>\n      <td>0.141928</td>\n      <td>0.858936</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.114600</td>\n      <td>0.147855</td>\n      <td>0.859815</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 78468\n  Batch size = 64\nSaving model checkpoint to ./hw2_rubert/checkpoint-2490\nConfiguration saved in ./hw2_rubert/checkpoint-2490/config.json\nModel weights saved in ./hw2_rubert/checkpoint-2490/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n***** Running Evaluation *****\n  Num examples = 78468\n  Batch size = 64\nSaving model checkpoint to ./hw2_rubert/checkpoint-4980\nConfiguration saved in ./hw2_rubert/checkpoint-4980/config.json\nModel weights saved in ./hw2_rubert/checkpoint-4980/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                 ):\n\u001b[1;32m   1658\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"Остановила после второй эпохи, потому что тестовый лосс вырос\nНо f1 стал уть-чуть выше, ура","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}
